{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uCt3OI-V2GGZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, RFE, SelectFromModel\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pUUBEDi64Vk",
        "outputId": "4e1cedfc-a3b6-45b8-ee42-8d5f15166566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 93312 entries, 0 to 93311\n",
            "Data columns (total 31 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Age                       93312 non-null  float64\n",
            " 1   Occupation                93312 non-null  int64  \n",
            " 2   Annual_Income             93312 non-null  float64\n",
            " 3   Monthly_Inhand_Salary     93312 non-null  float64\n",
            " 4   Num_Bank_Accounts         93312 non-null  float64\n",
            " 5   Num_Credit_Card           93312 non-null  float64\n",
            " 6   Interest_Rate             93312 non-null  float64\n",
            " 7   Num_of_Loan               93312 non-null  int64  \n",
            " 8   Delay_from_due_date       93312 non-null  float64\n",
            " 9   Num_of_Delayed_Payment    93312 non-null  float64\n",
            " 10  Changed_Credit_Limit      93312 non-null  float64\n",
            " 11  Num_Credit_Inquiries      93312 non-null  float64\n",
            " 12  Credit_Mix                93312 non-null  int64  \n",
            " 13  Outstanding_Debt          93312 non-null  float64\n",
            " 14  Credit_Utilization_Ratio  93312 non-null  float64\n",
            " 15  Credit_History_Age        93312 non-null  float64\n",
            " 16  Payment_of_Min_Amount     93312 non-null  int64  \n",
            " 17  Total_EMI_per_month       93312 non-null  float64\n",
            " 18  Amount_invested_monthly   93312 non-null  float64\n",
            " 19  Payment_Behaviour         93312 non-null  int64  \n",
            " 20  Monthly_Balance           93312 non-null  float64\n",
            " 21  Credit_Score              93312 non-null  int64  \n",
            " 22  Personal Loan             93312 non-null  int64  \n",
            " 23  Home Equity Loan          93312 non-null  int64  \n",
            " 24  Auto Loan                 93312 non-null  int64  \n",
            " 25  Mortgage Loan             93312 non-null  int64  \n",
            " 26  Payday Loan               93312 non-null  int64  \n",
            " 27  Credit-Builder Loan       93312 non-null  int64  \n",
            " 28  Student Loan              93312 non-null  int64  \n",
            " 29  Debt Consolidation Loan   93312 non-null  int64  \n",
            " 30  Not Specified             93312 non-null  int64  \n",
            "dtypes: float64(16), int64(15)\n",
            "memory usage: 22.1 MB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"./dataset.csv\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_val_metrics(clf, X, y, cv=5):\n",
        "    accuracy = []\n",
        "    f1 = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    kf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=36)\n",
        "    for train_idx, test_idx in kf.split(X, y):\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
        "        precision.append(metrics.precision_score(y_test, y_pred, average=None))\n",
        "        recall.append(metrics.recall_score(y_test, y_pred, average=None))\n",
        "        f1.append(metrics.f1_score(y_test, y_pred, average=None))\n",
        "    print(\"accuracy\", np.mean(accuracy))\n",
        "    print(\"precision\", np.mean(precision, axis=0))\n",
        "    print(\"recall\",np.mean(recall, axis=0))\n",
        "    print(\"f1\",np.mean(f1, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['Poor', 'Standard', 'Good']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(74649, 30) (74649,)\n"
          ]
        }
      ],
      "source": [
        "X = df.drop(['Credit_Score'], axis=1)\n",
        "y = df['Credit_Score']\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=36)\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Predict Poor  Predict Standard  Predict Good\n",
            "True Poor              3812              1365            78\n",
            "True Standard          1450              7600          1030\n",
            "True Good                82               972          2274\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Poor       0.71      0.73      0.72      5255\n",
            "    Standard       0.76      0.75      0.76     10080\n",
            "        Good       0.67      0.68      0.68      3328\n",
            "\n",
            "    accuracy                           0.73     18663\n",
            "   macro avg       0.72      0.72      0.72     18663\n",
            "weighted avg       0.73      0.73      0.73     18663\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(pd.DataFrame(metrics.confusion_matrix(y_test, y_pred, labels=np.unique(y_test)), \n",
        "             index=['True ' + x for x in labels], \n",
        "             columns=['Predict ' + x for x in labels]))\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.7358003955486311\n",
            "precision [0.72336067 0.76239781 0.67417215]\n",
            "recall [0.72282737 0.76510966 0.66750863]\n",
            "f1 [0.72308378 0.76373943 0.67074221]\n"
          ]
        }
      ],
      "source": [
        "cross_val_metrics(clf, X, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Độ chính xác khi sử dụng DecisionTree là khoảng 71%, cải thiện 4% so với việc không xử lí dữ liệu rỗng hoặc sai.\n",
        "\n",
        "Nhãn Good và Poor có f1-score cải thiện rõ rệt, có thể do việc xử lí dữ liệu làm các điểm phân cách giữa Standard và Good/Poor trở nên rõ ràng và chính xác hơn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Predict Poor  Predict Standard  Predict Good\n",
            "True Poor             21021                 0             0\n",
            "True Standard             0             40318             0\n",
            "True Good                 0                 0         13310\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Poor       1.00      1.00      1.00     21021\n",
            "    Standard       1.00      1.00      1.00     40318\n",
            "        Good       1.00      1.00      1.00     13310\n",
            "\n",
            "    accuracy                           1.00     74649\n",
            "   macro avg       1.00      1.00      1.00     74649\n",
            "weighted avg       1.00      1.00      1.00     74649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_train)\n",
        "print(pd.DataFrame(metrics.confusion_matrix(y_train, y_pred, labels=np.unique(y_train)), \n",
        "             index=['True ' + x for x in labels], \n",
        "             columns=['Predict ' + x for x in labels]))\n",
        "print(metrics.classification_report(y_train, y_pred, target_names=labels))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tuy nhiên, do số lượng feature đầu vào là rất nhiều (30 features), việc sử dụng một Decision Tree đơn giản có thể dễ dàng xảy ra overfit do dễ dàng tạo ra một cây quá đúng với tập train mà không khái quát được dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Predict Poor  Predict Standard  Predict Good\n",
            "True Poor              4384               863             8\n",
            "True Standard          1210              8160           710\n",
            "True Good                17               785          2526\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Poor       0.78      0.83      0.81      5255\n",
            "    Standard       0.83      0.81      0.82     10080\n",
            "        Good       0.78      0.76      0.77      3328\n",
            "\n",
            "    accuracy                           0.81     18663\n",
            "   macro avg       0.80      0.80      0.80     18663\n",
            "weighted avg       0.81      0.81      0.81     18663\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(pd.DataFrame(metrics.confusion_matrix(y_test, y_pred, labels=np.unique(y_test)), \n",
        "             index=['True ' + x for x in labels], \n",
        "             columns=['Predict ' + x for x in labels]))\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.8178155809533594\n",
            "precision [0.79534455 0.84012448 0.78862981]\n",
            "recall [0.84209933 0.8217589  0.76752084]\n",
            "f1 [0.81805154 0.83083459 0.77790318]\n"
          ]
        }
      ],
      "source": [
        "cross_val_metrics(clf, X, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ưu điểm:\n",
        "Kết quả được cải thiện rõ rệt sau khi phân tích xử lí dữ liệu và lựa chọn thuật toán phù hợp hơn với dữ liệu phức tap\n",
        "### Nhược điểm\n",
        "Số lượng feature vẫn rất nhiều khiến mô hình lớn và phức tạp"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
